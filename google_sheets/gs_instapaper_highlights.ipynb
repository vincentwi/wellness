{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Instapaper Highlights from Google Sheets\n",
    "### Bonus: Process and Export into Local Markdown Files\n",
    "\n",
    "This notebook will walkthrough getting you integrated with Google's Sheets API so you can pull data from Google Sheets into a data frame and use it accordingly. \n",
    "\n",
    "We are using a Google Sheet document created by IFTTT for Instapaper Highlights instapaper highlights to CSV and, in this particular case, saved locally into markdown files for each article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Go to https://developers.google.com/sheets/api/quickstart/python.\n",
    "- Click \"ENABLE THE GOOGLE SHEETS API\" and go through additional steps. \n",
    "- Configure below with sheet id and name. \n",
    "- Run Notebook\n",
    "\n",
    "NOTE: This should prompt you to open a URL to confirm access with Google. The end result should be a new file created called \"token.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "from datetime import date, datetime as dt, timedelta as td\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If modifying these scopes, delete the file token.pickle.\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sheet ID and target range (i.e. sheet name) of a sample spreadsheet.\n",
    "\n",
    "* Copy Sheet ID from URL of Targetted Sheet\n",
    "* Add ID to Configuration below as well as sheet name and/or range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure to Your Specific Sheet \n",
    "\n",
    "# SAMPLE_SPREADSHEET_ID = '1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms'\n",
    "# SAMPLE_RANGE_NAME = 'Class Data!A2:E'\n",
    "\n",
    "SPREADSHEET_ID = \"ADD_SHEET_ID_HERE\"\n",
    "RANGE_NAME = \"Sheet1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "creds = None\n",
    "# The file token.pickle stores the user's access and refresh tokens, and is\n",
    "# created automatically when the authorization flow completes for the first\n",
    "# time.\n",
    "if os.path.exists('token.pickle'):\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "# If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            'credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server()\n",
    "    # Save the credentials for the next run\n",
    "    with open('token.pickle', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "# build service\n",
    "service = build('sheets', 'v4', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data from Google Sheet and Return a List\n",
    "def get_gsheet_data(SPREADSHEET_ID, RANGE_NAME):\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                            range=RANGE_NAME).execute()\n",
    "    values = result.get('values', [])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "highlights_list = get_gsheet_data(SPREADSHEET_ID, RANGE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlights_list[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to df\n",
    "insta_highlights = pd.DataFrame(highlights_list[1:], columns = ['TimestampOrig', 'Article Title', 'Highlight', 'URL', 'Timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "insta_highlights.to_csv(\"data/instapaper_highlights.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Export Highlights to Markdown Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Local Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_directory = '/Users/my-user-name/Documents/clippings_and_quotes/'\n",
    "export_directory = 'data/export_test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Import and Data Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highlights = pd.read_csv(\"data/instapaper_highlights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimestampOrig</th>\n",
       "      <th>Article Title</th>\n",
       "      <th>Highlight</th>\n",
       "      <th>URL</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>August 17, 2018 at 11:07AM</td>\n",
       "      <td>The Making of a Corporate Athlete</td>\n",
       "      <td>A successful approach to sustained high perfor...</td>\n",
       "      <td>https://hbr.org/2001/01/the-making-of-a-corpor...</td>\n",
       "      <td>8/17/2018 11:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>August 17, 2018 at 11:08AM</td>\n",
       "      <td>The Making of a Corporate Athlete</td>\n",
       "      <td>Our efforts aim instead to help executives bui...</td>\n",
       "      <td>https://hbr.org/2001/01/the-making-of-a-corpor...</td>\n",
       "      <td>8/17/2018 11:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>August 17, 2018 at 09:32PM</td>\n",
       "      <td>We’re in a new age of obesity. How did it happ...</td>\n",
       "      <td>we ate more in 1976. According to government f...</td>\n",
       "      <td>http://www.theguardian.com/commentisfree/2018/...</td>\n",
       "      <td>8/17/2018 9:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>August 17, 2018 at 09:33PM</td>\n",
       "      <td>We’re in a new age of obesity. How did it happ...</td>\n",
       "      <td>According to a long-term study at Plymouth Uni...</td>\n",
       "      <td>http://www.theguardian.com/commentisfree/2018/...</td>\n",
       "      <td>8/17/2018 9:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>August 17, 2018 at 09:34PM</td>\n",
       "      <td>We’re in a new age of obesity. How did it happ...</td>\n",
       "      <td>we ate more in 1976, but differently. Today, w...</td>\n",
       "      <td>http://www.theguardian.com/commentisfree/2018/...</td>\n",
       "      <td>8/17/2018 9:34:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TimestampOrig  \\\n",
       "0  August 17, 2018 at 11:07AM   \n",
       "1  August 17, 2018 at 11:08AM   \n",
       "2  August 17, 2018 at 09:32PM   \n",
       "3  August 17, 2018 at 09:33PM   \n",
       "4  August 17, 2018 at 09:34PM   \n",
       "\n",
       "                                       Article Title  \\\n",
       "0                  The Making of a Corporate Athlete   \n",
       "1                  The Making of a Corporate Athlete   \n",
       "2  We’re in a new age of obesity. How did it happ...   \n",
       "3  We’re in a new age of obesity. How did it happ...   \n",
       "4  We’re in a new age of obesity. How did it happ...   \n",
       "\n",
       "                                           Highlight  \\\n",
       "0  A successful approach to sustained high perfor...   \n",
       "1  Our efforts aim instead to help executives bui...   \n",
       "2  we ate more in 1976. According to government f...   \n",
       "3  According to a long-term study at Plymouth Uni...   \n",
       "4  we ate more in 1976, but differently. Today, w...   \n",
       "\n",
       "                                                 URL           Timestamp  \n",
       "0  https://hbr.org/2001/01/the-making-of-a-corpor...  8/17/2018 11:07:00  \n",
       "1  https://hbr.org/2001/01/the-making-of-a-corpor...  8/17/2018 11:08:00  \n",
       "2  http://www.theguardian.com/commentisfree/2018/...   8/17/2018 9:32:00  \n",
       "3  http://www.theguardian.com/commentisfree/2018/...   8/17/2018 9:33:00  \n",
       "4  http://www.theguardian.com/commentisfree/2018/...   8/17/2018 9:34:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# date additions\n",
    "highlights['Timestamp'] = pd.to_datetime(highlights['Timestamp'])\n",
    "highlights['date'] = highlights['Timestamp'].apply(lambda x: x.strftime('%Y-%m-%d')) # note: not very efficient\n",
    "highlights['year'] = highlights['Timestamp'].dt.year\n",
    "highlights['month'] = highlights['Timestamp'].dt.month\n",
    "highlights['mnth_yr'] = highlights['Timestamp'].apply(lambda x: x.strftime('%Y-%m')) # note: not very efficient\n",
    "highlights['day'] = highlights['Timestamp'].dt.day\n",
    "highlights['dow'] = highlights['Timestamp'].dt.weekday\n",
    "highlights['hour'] = highlights['Timestamp'].dt.hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highlights Markdown Exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 total articles with highlights.\n"
     ]
    }
   ],
   "source": [
    "highlights_titles = highlights['Article Title'].unique()\n",
    "print('{:,} total articles with highlights.'.format(len(highlights_titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_article_highlights_file(article_title, directory=export_directory):\n",
    "    article_highlights = highlights[highlights['Article Title'] == article_title]\n",
    "    title = (article_highlights.iloc[0]['Article Title']).rstrip()\n",
    "    URL = (article_highlights.iloc[0]['URL'])\n",
    "    DateRead = (article_highlights.iloc[0]['date'])\n",
    "    title_stripped = (title.rstrip()\n",
    "                      .replace(\" \", \"_\")\n",
    "                      .replace(\":\", \"\")\n",
    "                      .replace(\",\", \"\")\n",
    "                      .replace(\"/\", \"\")\n",
    "                      .replace(\"(\", \"\")\n",
    "                      .replace(\")\", \"\")\n",
    "                      .replace(\"?\", \"\")\n",
    "                      .lower())\n",
    "    filename=(article_highlights.iloc[0]['Timestamp'].strftime('%Y%m%d%H%M') + \"_\" + title_stripped+\".md\")\n",
    "    filepath= directory+filename\n",
    "    \n",
    "    print(\"Printing... \" + filename)\n",
    "    file = open(filepath,\"w\") \n",
    "    file.write(\"# \" + title + \"\\n\")\n",
    "    file.write(\"Source: [\" + URL + \"](\"+ URL + \") \\n\")\n",
    "    file.write(\"Date Read: \" + DateRead + \"\\n\")\n",
    "    file.write(\"tags: #ArticleHighlights #ArticleRead \\n\")\n",
    "    file.write(\" \\n\") \n",
    "    file.write(\"### Highlights \\n\")\n",
    "    file.write(\" \\n\") \n",
    "    for index, row in article_highlights.iterrows():\n",
    "        file.write(str(row['Highlight']) + \" \\n\")\n",
    "        # file.write(\"p \" + str(row['num_pages']) + \" | \" + row['location'] + \" | \" + str(row['timestamp']) + \" \\n\")\n",
    "        file.write(\" \\n\")\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Test Book Title\n",
    "title_test = highlights_titles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing... 201904071150_gender_differences_in_suicide_-_wikipedia.md\n"
     ]
    }
   ],
   "source": [
    "# TEST Individual Book Export\n",
    "generate_article_highlights_file(title_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN\n",
    "# Loop through all books and generate individual markdown file with highlights\n",
    "#for i in highlights_titles:\n",
    "#    generate_article_highlights_file(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
