{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodreads Books Read Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Script to download and process User Books from Goodreads.com, especially your read books. \n",
    "\n",
    "Acknowledgement: This code is heavily indebted to and adopted from https://github.com/nladwa/goodreads-api\n",
    "\n",
    "For data analysis of your Good Reads Book Reading History, see: [goodreads_data_analysis.ipynb](https://github.com/markwk/qs_ledger/blob/master/goodreads/goodreads_data_analysis.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Authentification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get your user id and API Key from Goodreads.com.\n",
    "* Copy credentials-sample.json to credentials.json\n",
    "* Add your user id and api key and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"credentials.json\", \"r\") as file:\n",
    "    credentials = json.load(file)\n",
    "    goodreads_cr = credentials['goodreads']\n",
    "    user_id = goodreads_cr['USER_ID']\n",
    "    api_key = goodreads_cr['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import urllib.parse\n",
    "import xmltodict\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np, string, re, pytz\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_books_url(api_key, user_id, page, per_page):\n",
    "    base_url = \"https://www.goodreads.com/review/list/\"\n",
    "    args = urllib.parse.urlencode({\n",
    "            \"key\" : api_key,\n",
    "            \"v\" : 2,\n",
    "            # \"shelf\" : shelf_name,\n",
    "            \"page\" : page,\n",
    "            \"per_page\" : per_page\n",
    "        })\n",
    "    url = base_url + str(user_id) + \".xml?%s\" % (args)\n",
    "    return(url)\n",
    "\n",
    "def get_books_dict(**kwargs):\n",
    "\n",
    "    print(\"Collecting %s books via API for username \\\"%s\\\", be patient!\" % (kwargs[\"user_info\"][\"books_total\"], kwargs[\"user_info\"][\"user_name\"]))\n",
    "\n",
    "    books_collected, page, requests = 0, 1, [] # initialise variables\n",
    "\n",
    "    if \"per_page\" not in kwargs: kwargs[\"per_page\"] = 200\n",
    "\n",
    "    while books_collected < kwargs[\"user_info\"][\"books_total\"]:\n",
    "        books_url = get_books_url(kwargs[\"api_key\"], kwargs[\"user_id\"], page, kwargs[\"per_page\"])\n",
    "        books_data = urllib.request.urlopen(books_url).read()\n",
    "        books_dict = xmltodict.parse(books_data)\n",
    "        books_dict = books_dict[\"GoodreadsResponse\"][\"reviews\"][\"review\"]\n",
    "        requests.append(books_dict)\n",
    "        for item in books_dict:\n",
    "            books_collected = books_collected + 1\n",
    "        print(\"Books collected = %s/%s\" % (books_collected, kwargs[\"user_info\"][\"books_total\"]))\n",
    "        page = page + 1\n",
    "    print(\"Book collection complete\")\n",
    "    return(requests)\n",
    "\n",
    "def get_user_info_url(api_key, user_id):\n",
    "    base_url = \"https://www.goodreads.com/user/show/\"\n",
    "    args = urllib.parse.urlencode({\n",
    "            \"key\" : api_key\n",
    "        })\n",
    "    url = base_url + str(user_id) + \".xml?%s\" % (args)\n",
    "    return(url)\n",
    "\n",
    "def get_user_info(api_key, user_id):\n",
    "    user_info_url = get_user_info_url(api_key, user_id)\n",
    "    user_info_data = urllib.request.urlopen(user_info_url).read()\n",
    "    user_info_dict = xmltodict.parse(user_info_data)\n",
    "    books_total = int(user_info_dict[\"GoodreadsResponse\"][\"user\"][\"reviews_count\"][\"#text\"])\n",
    "    user_name = user_info_dict[\"GoodreadsResponse\"][\"user\"][\"user_name\"]\n",
    "    user_info = {\n",
    "        \"user_name\" : user_name,\n",
    "        \"books_total\" : books_total\n",
    "        }\n",
    "    return(user_info)\n",
    "\n",
    "def get_shelves(book):\n",
    "    return(book[\"shelves\"][\"shelf\"])\n",
    "\n",
    "def format_shelf_names(shelves):\n",
    "    # If one shelf, xmltodict reads in the tags as OrderedDict\n",
    "    if isinstance(shelves, OrderedDict):\n",
    "        return shelves[\"@name\"]\n",
    "    return(\", \".join(\n",
    "        shelf[\"@name\"] for shelf in shelves if \"@name\" in shelf\n",
    "    ))\n",
    "\n",
    "def get_author(review):\n",
    "    return(review[\"book\"][\"authors\"][\"author\"][\"name\"])\n",
    "\n",
    "def get_title(review):\n",
    "    return(review[\"book\"][\"title\"])\n",
    "\n",
    "def get_title_without_series(review):\n",
    "    return(review[\"book\"][\"title_without_series\"])\n",
    "\n",
    "def get_image_url(review):\n",
    "    return(review[\"book\"][\"image_url\"])\n",
    "\n",
    "def get_num_pages(review):\n",
    "    return(review[\"book\"][\"num_pages\"])\n",
    "\n",
    "def get_publication_year(review):\n",
    "    return(review[\"book\"][\"publication_year\"])\n",
    "\n",
    "def get_average_rating(review):\n",
    "    return(review[\"book\"][\"average_rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get User's Book Collection in GoodReads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'books_total': 1384, 'user_name': 'markwkoester'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info = get_user_info(api_key, user_id)\n",
    "user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting 1384 books via API for username \"markwkoester\", be patient!\n",
      "Books collected = 200/1384\n",
      "Books collected = 400/1384\n",
      "Books collected = 600/1384\n",
      "Books collected = 800/1384\n",
      "Books collected = 1000/1384\n",
      "Books collected = 1200/1384\n",
      "Books collected = 1384/1384\n",
      "Book collection complete\n"
     ]
    }
   ],
   "source": [
    "# get user's books\n",
    "books_dict_list = get_books_dict(api_key = api_key, user_id = user_id, user_info = user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine books into df\n",
    "books_to_concat = []\n",
    "for item in books_dict_list:\n",
    "    books_to_concat.append(pd.DataFrame(item))\n",
    "\n",
    "books = pd.concat(books_to_concat)\n",
    "# books.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# more processing and adding additional info\n",
    "shelves, authors, titles, titles_without_series, images_urls, nums_pages, publication_years, average_ratings = ([] for i in range(8))\n",
    "\n",
    "for item in books_dict_list:\n",
    "    for x in item:\n",
    "        shelves.append(format_shelf_names(get_shelves(x)))\n",
    "        authors.append(get_author(x))\n",
    "        titles.append(get_title(x))\n",
    "        titles_without_series.append(get_title_without_series(x))\n",
    "        images_urls.append(get_image_url(x))\n",
    "        nums_pages.append(get_num_pages(x))\n",
    "        publication_years.append(get_publication_year(x))\n",
    "        average_ratings.append(get_average_rating(x))\n",
    "        \n",
    "books[\"shelves\"] = shelves\n",
    "books[\"author\"] = authors\n",
    "books[\"title\"] = titles\n",
    "books[\"title_without_series\"] = titles_without_series\n",
    "books[\"image_url\"] = images_urls\n",
    "books[\"num_page\"] = nums_pages\n",
    "books[\"publication_year\"] = publication_years\n",
    "books[\"average_rating\"] = average_ratings\n",
    "\n",
    "# type addition\n",
    "books['started_at'] = pd.to_datetime(books['started_at'])\n",
    "books['read_at'] = pd.to_datetime(books['read_at'])\n",
    "books['date_added'] = pd.to_datetime(books['date_added'])\n",
    "books['date_updated'] = pd.to_datetime(books['date_updated'])\n",
    "\n",
    "books['rating'] = pd.to_numeric(books[\"rating\"])\n",
    "books['average_rating'] = pd.to_numeric(books[\"average_rating\"])\n",
    "books['read_count'] = pd.to_numeric(books[\"read_count\"])\n",
    "books[\"num_page\"] = pd.to_numeric(books[\"num_page\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this data is no longer needed so dropping it\n",
    "books.drop(['book'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total books\n",
    "len(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books.csv created\n"
     ]
    }
   ],
   "source": [
    "books.to_csv(\"data/books.csv\", index = False)\n",
    "print(\"books.csv created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Columns to process and nuance date read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"data/books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['started_at'] = pd.to_datetime(books['started_at'])\n",
    "books['read_at'] = pd.to_datetime(books['read_at'])\n",
    "books['date_added'] = pd.to_datetime(books['date_added'])\n",
    "books['date_updated'] = pd.to_datetime(books['date_updated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Unfortunatlely functions currently fail since many fields have NaT or missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to convert UTC to Shanghai time zone and extract date/time elements\n",
    "convert_tz = lambda x: x.to_pydatetime().replace(tzinfo=pytz.utc).astimezone(pytz.timezone('Asia/Shanghai'))\n",
    "get_year = lambda x: convert_tz(x).year\n",
    "get_month = lambda x: '{}-{:02}'.format(convert_tz(x).year, convert_tz(x).month) #inefficient\n",
    "get_day = lambda x: convert_tz(x).day\n",
    "get_hour = lambda x: convert_tz(x).hour\n",
    "get_day_of_week = lambda x: convert_tz(x).weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse out date and time elements as Shanghai time\n",
    "#books['ReadYear'] = books['read_at'].map(get_year)\n",
    "#books['ReadMonth'] = books['read_at'].map(get_month)\n",
    "#books['ReadDay'] = books['read_at'].map(get_day)\n",
    "#books['ReadHour'] = books['read_at'].map(get_hour)\n",
    "#books['ReadDOW'] = books['read_at'].map(get_day_of_week)\n",
    "# past_tasks = past_tasks.drop(labels=['completed_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total books read\n",
    "books_read = books[(books.read_count >= 1) & (books.shelves != 'currently-reading')].reindex()\n",
    "len(books_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Books with Date Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out books with null read_at date\n",
    "books_read_with_date = books_read[books_read['read_at'].notnull()].copy().reindex()\n",
    "books_read_with_date = books_read_with_date.sort_values(by=['read_at'])\n",
    "len(books_read_with_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse out date and time elements as Shanghai time\n",
    "books_read_with_date['read_at'] = pd.to_datetime(books_read_with_date['read_at'])\n",
    "books_read_with_date['read_timestamp'] = books_read_with_date['read_at'].map(convert_tz)\n",
    "books_read_with_date['year'] = books_read_with_date['read_at'].map(get_year)\n",
    "books_read_with_date['month'] = books_read_with_date['read_at'].map(get_month)\n",
    "books_read_with_date['day'] = books_read_with_date['read_at'].map(get_day)\n",
    "books_read_with_date['hour'] = books_read_with_date['read_at'].map(get_hour)\n",
    "books_read_with_date['mnth_yr'] = books_read_with_date['read_at'].apply(lambda x: x.strftime('%Y-%m')) # note: not very efficient\n",
    "books_read_with_date['dow'] = books_read_with_date['read_at'].map(get_day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books_all_read.csv created\n",
      "books_read_history.csv created\n"
     ]
    }
   ],
   "source": [
    "books_read.to_csv(\"data/books_all_read.csv\", index = False)\n",
    "print(\"books_all_read.csv created\")\n",
    "\n",
    "books_read_with_date.to_csv(\"data/books_read_history.csv\", index = False)\n",
    "print(\"books_read_history.csv created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
